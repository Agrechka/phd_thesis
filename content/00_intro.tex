\chapter{Introduction}
\label{chapter:introduction}

%\minitoc
\chapterwithfigures{\nameref*{chapter:introduction}}
%\chapterwithtables{\nameref*{chapter:introduction}}

\ifthenelse{\boolean{skipIntro}}{\endinput}{}

% \todo{1 + 2 + 3 doit etre fini pour mercredi matin !!}\\
% \todo{le 15 je mets un message aux repporteurs en disant que j'aurai une version finale le 1 aout, 15 j en retard}\\
% \todo{quand ils valident le jury alors faut que je valide sur adum}\\
% efficient image editing w/pretrained generative models 
% today; big models are available to use w/o having to re-train 
% state of the art 

% context IA / machine learning / CV 
% contributions -> edition ; what is the problem that i announced 
% exploit recent generative models 

% \epigraph{In a world once ruled by human hand\\
% Now machines have claimed the land\\
% Artificial intelligence reigns supreme\\
% Their circuits calculating the grand scheme.}{\textit{Automatically generated by ChatGPT}}

% \todo{intro - intro contrib tres coarse; comme related work mais tres coarse. environ 5 pages}

\emph{The camera doesn't lie}. We like to think of photographs as a perfect 
reflection of the Truth. They allow us to understand the present or truly 
glance back in time into history. 
Written documents can be easily altered, but surely not brilliantly complex photographs. 
Alas, the first edited photo in 1846 only shortly followed 
 the invention of photography itself in the 1820s~\citep{imageediting}. 
 During the 1920s, Stalin's regime led a massive photo 
 doctoring campaign, where 
opponents were quite literally (and realistically) erased from the history
 books 
through manual techniques like 
rephotographing photographs and chemical processing~\citep{stalin}. Digital 
image 
editing appeared in the 1980's, with PhotoShop emerging and quickly dominating 
the industry. Technologies such as color enhancement, colorization, and composition 
allowed photographers to create just about anything they imagined, provided they 
spend enough time. 
In the early 2010s, deep convolutional neural networks started dominating tasks like image classification~\citep{krizhevsky2012alexnet},
and early works in Generative Networks~\citep{Kingma2014, goodfellowgans} appeared shortly after. However, it was not until 
the early 2020s that truly realistic generation was made possible, and fast and intuitive 
photo editing applications were released. Today, \emph{semantic image editing}, 
where high-level image characteristics are easily modified, is finally possible (albeit not 
yet perfect). An 
image edit which may have taken hours just a few years ago can now be achieved in a matter of seconds. 
This thesis, started in 2020, had the unique opportunity to benefit from 
the recent groundbreaking advances in \emph{generative AI}. Indeed, our work
 followed and contributed to the recent trends in 
photo editing which allowed intuitive and semantic image editing. 



% It's rare for two simple letters - AI - to evoke such diverse and strong emotions, ranging from wonder and excitement to bewilderment,
% to fear and distress, and to flat-out disappointment. For a typical member of our modern Western society,  \ac{AI} is used
% all day, every day. Our music and movies are recommended to us by \ac{AI} recommender-systems \citep{toscher2009netflixprize}, 
% our driving directions are calculated by \ac{AI}\note{what is the technology for this ? cite}, our headphones use \ac{AI} 
% noise-cancelling technology \citep{noise_cancelling}, and we can ask \ac{AI} systems like "Siri" any questions using only our voice. 

\ac{AI} refers to the development of computer systems which are able to perform tasks which typically require 
human-intelligence. The term \ac{AI} is ambiguous and constantly evolving - what are the tasks which "typically require human-intelligence"? 
 For simplicity's sake, the \ac{AI} that we refer to in our work can be more precisely defined as 
\ac{ML}, which consists in (1) designing a parameterized mathematical model, a \ac{NN} $f_\theta$ as well as a loss function and 
(2) developing algorithms to calculate the parameters $\theta$ of the \ac{NN} which minimize the loss 
function using real-world data as the "ground-truth". In particular, complex and "deep" functions, referred to as a
\ac{DNN}, are defined using upwards of 175 billion learnable parameters \citep{gpt3}! This branch of \ac{AI}, \ac{DL}, 
has achieved remarkable results in recent years, which have fueled today's research trends of making bigger models and training 
with more data. In this work, we more specifically delve into the realm of \ac{CV}, which focuses on the understanding and manipulation of 
numerical images. Indeed, numerical images can be easily
represented to a computer in the form of RGB matrices.

%\ac{AI} research was born in the 1950's, where computers were learning to play checkers, solving algebra problems, 
% and speaking English. \note{continue with a bit of history}.

Throughout recent history, society at large went from waves of excitement and fear to sheer disappointment about the prospects 
of \ac{AI}. \ac{AI} confronted us with the uncomfortable question, "what does it mean to be human?". As \ac{AI} started beating 
humans in checkers~\citep{checkers_is_solved}, then chess~\citep{CAMPBELL200257}, and more recently Go~\citep{silver2017mastering}, 
humans reluctantly accepted that computers are 
superior in developing long-term strategy in games with simple rules and rewards. Likewise, language generation and translation, previously 
thought to be too complicated and nuanced for computers to understand, has achieved human-like capacities in recent years. Of course,
we have always clinged to the last untouchable area of unique humaneness: creativity. Machines couldn't possibly have the creativity to 
create images which match 
the genius of Leonardo da Vinci or Picasso. However, this again proved to be false in recent years with a computer-generated image winning an artwork
competition in 2022~\citep{artcomp} using the latest generative models. 

This thesis will explore this subfield of Generative \ac{AI}, and in particular, image editing with \ac{DNN}s.


\section{PhD Thesis Context}

\subsection{Meero}
Created in 2014, Meero is a French startup which specializes in digital image processing using \ac{AI}. Meero made history in 2019 when 
it raised a record-breaking \$230 million, becoming one of France's only "unicorns". Meero enhances real-world images from markets
ranging from real-estate to food photography to e-commerce. Meero proposes technology such as background-removal, color-enhancement, object 
removal and super-resolution. The majority for these image-manipulation algorithms relies on research in \ac{DL}.
It is important to note that there is often a disparity between the results proposed by state-of-the-art research for 
datasets and the expected image quality Meero's clients have. Firstly, research in the field often works with ``small" images 
(ImageNet~\citep{deng2009imagenet}, for example, uses 256x256 resolution). Meero's clients, on the other hand, require images of upwards of 5000x5000 resolution, 
which brings challenges for \ac{DL} applications.  Moreover, generated images in research papers often have 
visible artifacts, which is acceptable in the context of research but unacceptable for clients expecting a beautiful 
image. A goal of this thesis is to bridge the gap between research and real-world applicability.

\begin{figure}[tb]
    \begin{center}
        \includegraphics[width=0.5\linewidth]{images/intro/giraffe.png}
    \end{center}
    \caption{Using Stable Diffusion~\citep{rombach2022high} to generate a photo of "a giraffe riding a unicycle on the moon"}
    \label{fig:diffusion_example}
\end{figure}



\subsection{Image Generation}
Image generation has seen phenomenal and almost unbelievable progress in recent years, mainly due to improvements in model architecture, 
increasing model capacity, and increasing the size of training datasets.
In 2013, the Variational Auto-Encoder (\ac{VAE})~\citep{Kingma2014} allowed blurry, low-quality results of images in a particular domain. In 2014,
\ac{GAN}s were introduced, which Yann LeCun, a \ac{DL} pioneer, described as “the most interesting idea 
 in the last 10 years in Machine Learning”. Indeed, the "generator" was trained not alone, but in unison with another network, the "discriminator",
 both trained "adversarially" (their respective objectives are opposing). The \ac{GAN} frenzy lasted until the start of the 2020's, and for the
  first time  allowed truly realistic generations of images in restricted domains, particularly faces. Indeed, the popular website
   \urlstyle{thispersondoesnotexist.com} displayed the uncannily realistic face generations using StyleGan~\citep{karra2019stylegan, karra2020stylegan2}.
    However, \ac{GAN}s struggled with 
   larger and more diverse domains, leaving room for other architectures, like the \ac{ViT}~\citep{esser2021taming, ramesh2021zero, ding2021cogview}.
    Only recently,
   remarkable progress was made with \ac{DDPM}~\citep{ho2020denoising,nichol2021glide, rombach2022high, ramesh2022hierarchical, saharia2022photorealistic}. 
   These models, as we will later see, have a simple loss function and allow stable training even when scaling up their architecture.
   As \ac{DDPM}s quickly made their way to becoming state-of-the-art for various datasets, particularly ImageNet~\citep{deng2009imagenet}, researchers
   started to scale up the models further and train them on massive billion element text-image datasets. The past few years have welcomed
   a true revolution in Image Generation, allowing generation of images which are not only realistic, but also of unprecedented diversity.
   Indeed, a completely imaginary and absurd prompt such as "a giraffe riding a unicycle on the moon" actually produces a  plausible 
   output image, as shown in \ref{fig:diffusion_example}.



   

\subsection{Image Editing}
Before digital photography, photographs were created in multiple steps: first, light interacts with light-sensitive chemicals on 
a camera's film, which produces a \emph{negative} photograph; then, the negative photograph can be developed into a \emph{positive} 
photograph in a darkroom with the help of chemicals. Before digital editing, real-image editing 
consisted in manually manipulating the negative 
photograph before further processing it to develop the positive image. These practices date back to the 1840s, almost 200 years ago.

In contrast, real-image editing with \ac{DL} has a relatively recent history, mainly taking off following the introduction of \ac{GAN}s after 2014.
Image editing has foundations as an Image-to-Image translation problem, where a \ac{DNN} is trained to learn the transformations from 
one domain to another~\citep{isola2017image}. These edits were initially limited to edits akin to style-transfer, like transforming 
photographs to paintings or night images to day images, and often presented visible artifacts.
Over time, image-editing techniques became more elaborate, where the editing operation could change  specific attributes 
(like man$\rightarrow$woman)~\citep{choi2020stargan} or use a user-given text prompt~\citep{li2020manigan}. These methods still struggled with artifacts 
and fidelity to the input image, though, since changes were effected in a fully-convolutional manner. More recently, the latest 
\ac{GAN}s~\citep{karra2019stylegan, karra2020stylegan2} 
were shown to have localized and meaningful editing capabilities via their latent code, allowing semantic edits like man$\rightarrow$woman 
while more faithfully preserving the initial image. Other works perform manipulation of the learned weights within a trained network for 
even more controllable generation~\citep{bau2020rewriting}. Using a pre-trained generative prior, like a \ac{GAN} or \ac{DDPM}, has the advantage 
of leveraging the learned relationships in a large and powerful network. Training an editing network from scratch, however, requires large amounts of data and 
computation power, while only allowing limited types of editing instructions. Moreover, manipulating the internal weights and latent code of a 
pre-trained network typically allows for more natural edits than a trained editing network. However, generalizing these edits to real images is not straightforward, 
as we need an effective way to encode a real image into the network. Moreover, using a pre-trained generative network may limit us to the distribution of the 
training dataset. 
In this thesis, we explore these problems when leveraging
and manipulating the compact representations of pre-trained generative priors to effectuate target editing operations. 

Our use of \ac{DNN}s
for image editing in 2023 can be seen as an amusing echo to the image editing performed almost 200 years ago. Indeed, if the compact negative image 
is seen as the "latent image" of traditional photography, traditional image editing techniques consisted in manipulating this "latent image" before "decoding" 
it into a positive image. Likewise, 
we focus on manipulating the latent vectors of various generative models while striving to push the generated image to be as natural as possible.


\section{Contributions}

Editing real images with \ac{AI} is a unique case where the "artificial" meets "human". 
While a fake image 
which is entirely generated by an \ac{AI} system is trained to be harmonious by the model, an edited image
requires a generation which is not only realistic but also faithful to the original image. This 
tradeoff between \emph{editing success} and \emph{fidelity to the original image} is a recurrent theme which we will see throughout 
our thesis, both to build our methods as well as evaluate them. We tackle several different families of editing operations (attribute editing, 
text-guided editing, and inpainting) and leverage different generative models to accomplish our task. 

Throughout this thesis, we would like the reader to be aware of the three objectives we have when it comes to image editing:

\begin{enumerate}
    \item Fidelity to the input image
    \item High quality output image 
    \item Fidelity to the edit operation 
\end{enumerate}

We approach image editing from several different lenses, which we quickly summarize  here:

\begin{itemize}
      \item \autoref{chapter:magec}: \nameref{chapter:magec}\\
            We first approach real image editing by generalizing \ac{GAN} latent manipulation techniques 
            to real images. Indeed, latent manipulation produces meaningful and realistic edits to 
            generated images, but requires a real image to first be inverted into a \ac{GAN} before applying the same techniques. 
            However, naively inverting an image into a \ac{GAN} produces poor edits of the image. We analyze the reasons for this and we 
            propose a better strategy for \ac{GAN} inversion, with editability as our motivation. The work in this chapter has led to the following 
            conference publication:
            \begin{itemize}
                \item \fullcite{grechka2021magecally}
            \end{itemize}


      \item \autoref{chapter:flexit}: \nameref{chapter:flexit}\\
            While our inversion strategy allowed meaningful edits, it still struggled with 
            out-of-domain images with regards to the pre-trained \ac{GAN}. In this chapter,  we  decide to 
            circumvent inversion altogether and optimize the latent vector of an autoencoder to 
            perform text-given edits. Our method relies on well-studied regularizers to produce a 
            high-quality edited image. The work in this chapter has led to the following 
            conference publication:
            \begin{itemize}
                  \item \fullcite{couairon2022flexit}
            \end{itemize}

      \item \autoref{chapter:gradpaint}: \nameref{chapter:gradpaint}\\
            While the previous work can be flexibally applied to any given image and text-prompt, the 
            lack of a strong generative prior sometimes makes the editing operation fail. In this chapter, 
            we look into the use of using a \ac{DDPM} for the specific task of inpainting. Indeed, we can 
            guarantee fidelity to the input image while producing a high-quality generation thanks to the 
            pre-trained \ac{DDPM}. Our work is currently in submission:
            \begin{itemize}
                  \item \fullcite{grechka_gradpaint}
            \end{itemize}
\end{itemize}




% In this thesis introduction, using layman terms, we describe Artificial Intelligence, and,
% in particular, one of its instances: Deep Learning. Then, we lay out the challenges of this
% thesis and our contributions.

% %\section{Artificial Intelligence}

% \textbf{The idea of thinking machines} began in the previous century, from Karel Çapek's invention
% of the "\textit{robot}" to the 1956's Dartmouth workshop passing by Turing \& von Neumann's
% reflections. Despite suffering from multiple "AI winters" filled with disappointments and
% criticisms, Turing's prediction on the rising importance of \ac{AI} proved to be right as the first
% and the second decades of the XXI century saw the advent of respectively \acf{ML}
% \citep{bishop2006prml} and \acf{DL} \citep{goodfellow2016deeplearningbook}, two major subfields of
% \ac{AI}, related to statistical learning theories.

% Providing \textbf{a definition of \ac{AI}} is difficult, but its foremost domains, \ac{ML} and
% \ac{DL}, can be defined as statistical algorithms that can improve automatically through experience
% and the use of data. These methods are already ubiquitous: speech recognition enabling us to control
% devices remotely \citep{amodei2016deepspeech2}, recommender systems proposing movies according to
% our taste \citep{toscher2009netflixprize}, automatic translation \citep{vaswani2017transformer},
% face recognition \citep{schroff2015facenet}, autonomous driving \citep{sun2020waymodataset}, \etc.
% Less known but still useful applications comprise accelerated physics simulation
% \citep{breen2020threebody}, protein folding prediction \citep{jumper2021alphafold}, molecule
% toxicity estimation \citep{nih2019toxchallenge}, data center cooling
% system \citep{evans2016datacentercooling}, control of the magnetic coils of a nuclear fusion reactor
% \citep{degrave2022nuclearreactor}, \etc.

% \ac{AI} is increasingly more important in our daily lives with some applications raising
% \textbf{ethical concerns}: face recognition biased towards some populations
% \citep{grother2019facerecoethic}, loan grants \citep{anglekar2021loangrantml}, medical diagnosis
% \citep{lazzazabal2020medicalbias}, justice advice \citep{russel2020justicefairness}, biased chatbots
% \citep{sheng2019lmbias}, \etc. Therefore, we must pay a particular interest in the potential impact
% of this new technology. Towards this goal, people from diverse backgrounds must participate in the
% creation of such technology, and standardization bodies \citep{tommasi2021fairness} should advise
% what types of \ac{AI} systems can be used in which scenarios \citep{gebru2019aiethichandbook}.

% \section{PhD Thesis Context}

% I now contextualize my thesis with relation to my sponsor, how it influenced our research, and what
% challenges we have aimed to tackle.

% \paragraph{Heuritech} This thesis was sponsored by the Parisian startup
% Heuritech\footnote{\url{https://heuritech.com}} as a \textit{CIFRE PhD}. The company analyzes social
% networks such as Instagram and Weibo, recognizes the clothes in pictures, estimates
% volumes of fine-grained types of garments, and finally forecasts future trends. The company's
% \acf{CV} models must recognize an ever-growing number of entities from features (\eg knitted, blue
% color, short cut) to brand models (\eg Nike Air Max, Adidas Stan Smith, Puma Suede). This
% requirement leads to two problems: \textbf{(1)} the time spent to re-train a model is growing
% linearly, and \textbf{(2)} learning a new entity can incur a performance loss on previously learned
% entities.

% \paragraph{Continual Learning} is a field that emerged in the 1990s but saw renewed interest only
% very recently around the second half of the 2010s. The goal is to deal with datasets that evolve
% through time. This evolution can take many forms, including adding new entities to predict in a
% classification task (\eg learning sneaker brands, then high-heel brands) or adding samples from new
% sources (\eg commercial photoshoot then images from social media). Unfortunately, current
% State-of-the-Art models struggle to learn continually from new data without losing performance on
% previously seen data. This loss is so critical that the literature nicknamed it ``\textit{catastrophic
%       forgetting}'' \citep{robins1995catastrophicforgetting,french1999catastrophicforgetting}. Multiple
% methods can reduce this forgetting, including rehearsal and constraints. Rehearsal involves
% reviewing previously learned knowledge, as a human student would \textit{rehearse} the last
% semester's course. However, this rehearsal is often limited in order to reduce computational cost
% and because past data may not always be available for a variety of reasons, including privacy. On
% the other hand, constraints enforce the model to keep a similar \textit{behavior} as it learns new
% concepts, but defining the optimal constraint is not trivial.

% \section{Contributions}

% This PhD thesis is structured around solving catastrophic forgetting in continual settings. We
% considered various specific situations and approaches declined in several chapters:

% \begin{itemize}
%       \item \autoref{chapter:regularization}: \nameref{chapter:regularization}\\
%             We first propose strategies to tackle catastrophic forgetting in deep neural neworks in
%             the context of the image classification. Our main goal is to constrain the evolution of the
%             network parameters during the continual training to be relatively rigid while also
%             avoiding completely freezing the network. The work in this chapter has led to two
%             conference publications:
%             \begin{itemize}
%                   \item \fullcite{douillard2020podnet}
%                   \item \fullcite{douillard2020ghost}
%             \end{itemize}

%       \item \autoref{chapter:segmentation}: \nameref{chapter:segmentation}\\
%             Then, we extend our focus to the task of semantic segmentation. We show that this
%             context brings new challenges, and we propose multiple complementary approaches to tackle
%             them. The work in this chapter has led to one conference publication and one submission
%             to a journal:
%             \begin{itemize}
%                   \item \fullcite{douillard2020plop}
%                   \item \fullcite{douillard2021objectrehearsal}
%             \end{itemize}

%       \item \autoref{chapter:dynamic}: \nameref{chapter:dynamic}\\
%             Finally, in our last chapter, we consider the impact of the neural network architecture
%             for continual learning and in particular propose using the recent Transformer. The work
%             in this chapter has led to a conference publication:
%             \begin{itemize}
%                   \item \fullcite{douillard2021dytox}
%             \end{itemize}
% \end{itemize}

