\cleardoublepage
\setcounter{page}{1}

\chapter{Abstract}

I first review the existing methods based on regularization for continual learning. While
regularizing a model's probabilities is very efficient to reduce forgetting in large-scale datasets,
there are few works considering constraints on intermediate features. I cover in this chapter two
contributions aiming to regularize directly the latent space of \acs{ConvNet}. The first one,
PODNet, aims to reduce the drift of spatial statistics between the old and new model, which in
effect reduces drastically forgetting of old classes while enabling efficient learning of new
classes. I show in a second part a complementary method where we avoid pre-emptively forgetting by
allocating locations in the latent space for yet unseen future classes.

Then, I describe a recent application of \acf{CIL} to semantic segmentation. I show that
the very nature of \acf{CSS} offer new specific challenges, namely forgetting on large
images and a background shift. We tackle the first problem by extending our distillation
loss introduced in the previous chapter to multi-scales. The second problem is solved by
an efficient pseudo-labeling strategy. Finally, we consider the common rehearsal learning,
but applied this time to \ac{CSS}. I show that it cannot be used naively because of memory
complexity and design a light-weight rehearsal that is even more efficient.

Finally, I consider a completely different approach to continual learning: dynamic networks
where the parameters are extended during training to adapt to new tasks. Previous works on
this domain are hard to train and often suffer from parameter count explosion. For the
first time in continual computer vision, we propose to use the Transformer architecture:
the model dimension is mostly fixed and shared across tasks, except for an
expansion of learned task tokens. With an encoder/decoder strategy where the decoder
forward is specialized by a task token, we show state-of-the-art robustness to forgetting
while our memory and computational complexities barely grow.



Image editing has a rich history 


\cleardoublepage


\chapter{R\'esum\'e}

\selectlanguage{french}

L'édition des images a une histoire riche, datant d'il y a plus de deux siècles. 
Neansmoins, l'édition "classique" des images nécessite une fort maitrise artistique
ainsi que du temps de l'ordre des heures pour chaque image qu'on souhaite modifier.
Durant des années récentes, des importants progrès en modélisation générative ont 
permit une synthèse d'image réaliste et de haute qualité. Cependant, la tache de l'édition 
d'une image réelle consiste à la fois à synthésiser une nouvelle charactéristique de 
l'image et à la fois à garder une autre partie fidèle à l'origine. 

Nous abordons dans cette thèse plusieurs façons à éditer des images en exploitant 
trois différentes familles de modèles génératifs: les GANs, les auto-encodeurs 
variationnels,  et 
les modèles de diffusion. 

Dans un premier temps, nous étudions comment utiliser un GAN pré-entrainé pour éditer 
une image réelle. En effet, des méthodes pour éditer une image générée d'un GAN sont 
bien connues, mais se généralisent mal pour des images réelles. Nous étudions la raison 
pour ceci et proposons une solution pour mieux projetter une image réelle dans un GAN 
pour qu'il soit bien éditable.

Dans un second temps, nous utilisons les autoencodeurs variationnels avec quantification 
vectorielle pour directement avoir une répresentation compacte de l'image (ce qu'il nous 
manquait avec les GANs) et optimiser le vecteur latent de celle-ci pour se rapprocher 
d'un texte voulu. Nous recherchons à contraindre ce problème qui pourrait à premier vu 
être suscepbitle à des exemples adversarials. Nous proposons une façon pour bien choisir 
les hyperparamètres en fonction de la fidelité et édition des images éditées. Nous proposons
un protocol d'évaluation robuste et montrons l'intérêt de notre méthode.

Enfin, dans un troisième temps, nous traitons l'édition d'image comme un problème 
particulier d'inpainting. Nous voulons synthétiser une partie de l'image et garder le 
reste de l'image intact. Pour ceci, nous exploitons des modèle de diffusion pré-entrainés 
et se basent sur la méthode d'inpainting classique avec ceci en remplacant à chaque étape 
du processus du débruitage la partie qu'on ne souhaite pas modifier par l'image réelle bruitée.
Cependant, cette méthode est susceptible à une desharmonisation entre la partie 
générée et la partie réelle. Nous proposons une méthode basée sur le calcul de gradient 
d'une fonction qui calcule l'harmonisation entre les deux parties. Nous guidons le 
processus de débruitage avec ce gradient.







Depuis le début des années 2010 la recherche en apprentissage automatique a orienté son attention
vers les efficaces réseaux de neurones profonds. Plus particulièrement, toutes les tâches de vision
par ordinateur utilisent désormais des réseaux convolutionnels. Ces modèles apprennent à détecter
des motifs d'abord simples (contours, textures) puis de plus en plus complexes jusqu'à apprendre
le concept d'objets en particulier.

Malgré les grandes avancées dans le domaine des réseaux de neurones profonds, un problème important
subsiste : comment apprendre une quantité croissante de concepts, à la manière d'un élève durant sa
scolarité, sans oublier les précédentes connaissances. Ce problème d'apprentissage continu est
complexe : si non traité, les réseaux de neurones oublient de façon catastrophique.

J'ai pu dans un premier temps développer plusieurs méthodes pour forcer un comportement similaire
entre la version du modèle ayant appris de nouveaux concepts et sa précédente itération.
Contrairement au reste de la littérature, qui imposait des contraintes sur le comportement final du
modèle, je me suis intéressé aux représentations internes.

Dans un second temps, j'ai considéré l'apprentissage continu pour la tâche de segmentation
sémantique. Cette tâche complexe possède des problèmes inédits dans un contexte continu en plus de
l'oubli catastrophique. J'ai pu proposer plusieurs approches complémentaires pour les résoudre. Plus
précisément : une nouvelle méthode de contraintes, une technique de pseudo-annotations et une
manière efficace de révisions d'objets.

Et enfin, dans un troisième et dernier temps, je m'intéresse aux réseaux de neurones dynamiques,
pouvant créer de nouveaux neurones à travers leur existence pour résoudre un nombre croissant de
tâches. Les méthodes précédentes grandissent avec peu de contrôles, résultant en des modèles
extrêmement lourds, et souvent aussi lents. Donc, en m'inspirant des récents \textit{transformers},
j'ai conçu une stratégie dynamique avec un coût pratiquement nul, mais ayant malgré tout des
performances à l'état-de-l'art.

\selectlanguage{english}

\cleardoublepage
\chapter{Remerciements}

Matthieu,...

Guillaume, 
Gaetan, 

Jean, thanks for leaving me alone to write a phD with a newborn baby 
while you got drunk with your collegues. 

Jean, thank you for being there through the stress, the tears, the joy. 
Thank you for keeping my side of the bed warm for me during deadlines.
Thank you for the hundreds of cups of tea you made me. You are sweeter
than honey.

Émile, thank you for showing me what the purest forms of curiosity and 
determination look like. You kept my final phD days busier than I could 
sometimes handle, but your morning toothless smiles fueled me more than 
any full-night of sleep could have. I love you.


I would like to thank everybody 
Matthieu 
I would like to thank the students I taught during these years, who gave me fresh eyes
I would like to thank my family and my friends for their support. My brother

Jean, thank you for being here throughout the years. Thank you for 


\selectlanguage{french}

Je souhaite remercier tous ceux qui m'ont aidé à réaliser cette thèse.

Dans un premier temps : Matthieu pour m'avoir supervisé tout au long de ces trois ans de thèse,
pour m'avoir fait découvrir le monde de la recherche et avoir supporté mes avis têtus. J'ai beaucoup
appris et j'en sors grandi. Charles et Tony pour m'avoir fait confiance et permis de faire ce
doctorat avec Heuritech. Et plus particulièrement Charles, pour m'avoir initié au Deep Learning.

Je remercie aussi le jury de cette thèse pour avoir relu mon manuscrit et m'avoir accordé leur temps
pour cette soutenance de thèse.

Je veux aussi remercier tous mes collègues dont leurs discussions ont toujours été enrichissantes
aussi bien sur le plan du travail que de l'humain (dans des parties de babyfoot endiablées). Parmi
les \textit{Chordettes}: Corentin Dancette, Rémi Cadene, Alexandre Ramé, Antoine Saporta, Guillaume
Couairon, Asya Grechka, Yifu Chen, Rémy Sun, et Ahmed Mazari. Chez Heuritech: Thomas Robert (pour sa
gentillesse infinie), Emilien Garreau, Antoine Hoorelbeke, Paul Morel, Florent Mercier, et Oscar
Bouvier. Et enfin aussi Timothée Lesort, Fabio Cermelli, Eduardo Valle et Arnaud Dapogny pour leur
collaboration. Plus largement je remercie aussi l'ensemble de l'équipe du MLIA et Heuritech pour
leur support et la bonne ambiance qu'ils ont apporté.

Enfin, je veux remercier mes proches. À Jordan et Camille qui m'ont tant soutenu cette dernière
année. À David, Hugo, Alexandre, Thibault et Marie-Anne, Florent, Sarasvati, Benjamin, Charlotte,
et tous ceux avec qui j'ai pu passer de bons moments. À ma famille, ma sœur Julie, mon père, ma
mère et mes grand-parents pour leur soutien durant ces 26 ans de vie. J'insiste particulièrement
sur l'éducation et la passion des sciences transmises par ma mère et ma grand-mère. Sans cela, rien
n'aurait été possible. Et enfin merci à Epsilon pour ses ronronnements d'encouragement.


\selectlanguage{english}
