\cleardoublepage
\setcounter{page}{1}

\chapter{Abstract}

Real image editing has a rich history, dating back about two centuries. Traditional digital image 
editing requires strong artistic skills and significant time (several hours for each image 
which we wish to edit). Recently,  important progress has 
been made in generative modeling which allowed the creation of realistic and high-quality images. 
However, 
the task of image editing has been less studied. Image editing consists in 
simultaneously synthesizing new characteristics while preserving original image attributes intact. 
This inherent tradeoff between synthesis and preservation renders the task particularly difficult.

In this thesis, we approach the task through different angles, exploiting three different families of 
generative models: \ac{VAE}, \ac{GAN} and \ac{DDPM}.

We first study how to use a pre-trained \ac{GAN} to modify a real image.
While latent-space manipulation methods are well-studied to modify a \ac{GAN}-generated image, 
they extend poorly to real images. We study the reasons for this and propose 
to enforce editability directly into the \ac{GAN} inversion loss term, which results in 
high-quality edits.

Then, we leverage a vector-quantized variational autoencoder (VQ-GAN) to obtain a compact representation of an image. 
The goal is to optimize this latent vector to match a user-given target text prompt. We use CLIP text and image encoders
to represent images and text in a joint representation space. We thoroughly study the use of 
regularizers to encourage strong fidelity to the original image as well as coherent editing to the text prompt.
We propose a robust and standardized evaluation protocol for text-guided editing.

Finally, we leverage \ac{DDPM}s, where we study the particular task of inpainting. 
We base our method on the standard \ac{DDPM} inpainting procedure, which, at each step of the denoising process, 
replaces the region which should stay intact by the real image noised at this level. While \ac{DDPM}s naturally blend these two regions due to their iterative 
denoising nature, the blending is not "fast enough" which results in disharmonized images. We define our custom harmonization loss 
and use its gradient to update the intermediate latent noise maps in each step of the denoising process, resulting in high-quality results for various 
models.


\cleardoublepage


\chapter{R\'esum\'e}

\selectlanguage{french}

L'édition des images a une histoire riche, datant d'environ deux siècles. 
L'édition digitale "classique" des images nécessite une forte maitrise artistique
et beaucoup de temps (plusieurs heures pour chaque image que l'on souhaite modifier).
Récemment, d'importants progrès en modélisation générative ont 
permis de créer des images réalistes de haute qualité. Cependant, la tâche d'édition 
d'une image réelle est moins étudiée. Elle consiste à la fois à synthésiser une nouvelle charactéristique de 
l'image et à garder une autre partie fidèle à l'originale, ce qui rend la tâche 
particulièrement ardue.

Dans cette thèse, nous abordons cette tâche d'édition sous différents angles, en exploitant 
trois familles de modèles génératifs: les \ac{VAE}, les \ac{GAN} et les \ac{DDPM}.

Nous étudions  dans un premier temps comment utiliser un \ac{GAN} pré-entrainé pour éditer 
une image réelle. En effet, les méthodes pour éditer les images générées pour un \ac{GAN} sont 
bien connues, mais se transposent mal au cas des images réelles. Nous en étudions les raisons 
 et proposons une solution pour mieux projeter une image réelle dans l'espace latent du \ac{GAN} 
afin d'assurer une édition de qualité.

Ensuite, nous utilisons des autoencodeurs variationnels avec quantification 
vectorielle (VQ-GAN) pour avoir une répresentation compacte de l'image. 
L'objectif est d'optimiser le vecteur latent de celle-ci pour se rapprocher 
d'un texte exprimé comme une requête pour l'édition. 
Nous utilisons des encodeurs CLIP  pour représenter l'image et le texte dans un espace commun.
Nous proposons une façon pour optimiser 
les hyperparamètres assurant une grande fidelité à l'image originale et une édition cohérente à la requête textuelle. 
Nous proposons
un protocole d'évaluation robuste et montrons l'intérêt de notre méthode.

Enfin, dans un troisième temps, nous traitons l'édition d'image comme un problème 
particulier d'inpainting. Nous exploitons un \ac{DDPM} pré-entrainé 
et nous nous basons sur la méthode d'inpainting classique, en remplacant à chaque étape 
du processus de débruitage la région qu'on ne souhaite pas modifier par l'image réelle bruitée.
Cependant, cette méthode est susceptible d'introduire une distorsion entre la région 
générée et la région réelle. Nous proposons une méthode basée sur le gradient 
d'une fonction assurant la cohérence entre les deux régions. Nous guidons le 
processus de débruitage avec ce gradient. Nous produisons des images de grande qualité pour différents modèles.








\selectlanguage{english}

\cleardoublepage
\chapter{Acknowledgments}

It's with a bittersweet sigh of relief that I write these final words of gratitude in this thesis. 
From the bottom of my heart, I want to thank the following people\dots

First and foremost, Matthieu, thank you, for being the best supervisor a phD candidate could 
hope to have. Thank you for your advice, your humor, your patience, your words of kindness in difficult situations. 
Thank you for building such an incredible and talented team. If we should "surround ourselves with people who are smarter than us", then I 
lucked out. Thank you, Matthieu, for helping me grow into the researcher and the person 
I am today. 

Thank you to the \textit{Chordettes} team. Thank you for the thought-provoking conversations and 
fooseball breaks. Particularly, thank you Guillaume, for all of our stimulating discussions, your 
great ideas, your scientific rigour,  and your calm demeanor in times of stress.  Thank you for your invaluable help 
in our work.

Thank you to my team in Meero. While many have come and gone, you all made a mark in my journey. 
I want to especially thank Gaétan, who has endlessly helped me in understanding papers, debugging my code, 
and sharing the inevitable frustrations of phD life. You will soon finish too, and you'll be the greatest 
3D specialist the world has to offer.

Thank you to my mom and Max and dad, whose personal phD stories lit up mine. Thank you 
Jeka, for helping me with the experiments for GradPaint. You're the best.

Thank you Jean. Thank you for being there through the stress, the tears, the joy. 
Thank you for the hundreds of cups of tea you made me. 
Thank you for keeping my side of the bed warm for me during deadlines.
You are sweeter than honey.

Émile, thank you for showing me what the purest forms of curiosity and 
determination look like. You kept my final phD days busier than I could 
sometimes handle, but your morning toothless smiles fueled me more than 
any full-night of sleep could have. I love you.

% \todo{}

% Matthieu,...

% Guillaume, 
% Gaetan, 

% Jean, thanks for leaving me alone to write a phD with a newborn baby 
% while you got drunk with your collegues. 

% Jean, thank you for being there through the stress, the tears, the joy. 
% Thank you for keeping my side of the bed warm for me during deadlines.
% Thank you for the hundreds of cups of tea you made me. You are sweeter
% than honey.

% Émile, thank you for showing me what the purest forms of curiosity and 
% determination look like. You kept my final phD days busier than I could 
% sometimes handle, but your morning toothless smiles fueled me more than 
% any full-night of sleep could have. I love you.


% I would like to thank everybody 
% Matthieu 
% I would like to thank the students I taught during these years, who gave me fresh eyes
% I would like to thank my family and my friends for their support. My brother

% Jean, thank you for being here throughout the years. Thank you for 


% \selectlanguage{french}

% Je souhaite remercier tous ceux qui m'ont aidé à réaliser cette thèse.

% Dans un premier temps : Matthieu pour m'avoir supervisé tout au long de ces trois ans de thèse,
% pour m'avoir fait découvrir le monde de la recherche et avoir supporté mes avis têtus. J'ai beaucoup
% appris et j'en sors grandi. Charles et Tony pour m'avoir fait confiance et permis de faire ce
% doctorat avec Heuritech. Et plus particulièrement Charles, pour m'avoir initié au Deep Learning.

% Je remercie aussi le jury de cette thèse pour avoir relu mon manuscrit et m'avoir accordé leur temps
% pour cette soutenance de thèse.

% Je veux aussi remercier tous mes collègues dont leurs discussions ont toujours été enrichissantes
% aussi bien sur le plan du travail que de l'humain (dans des parties de babyfoot endiablées). Parmi
% les \textit{Chordettes}: Corentin Dancette, Rémi Cadene, Alexandre Ramé, Antoine Saporta, Guillaume
% Couairon, Asya Grechka, Yifu Chen, Rémy Sun, et Ahmed Mazari. Chez Heuritech: Thomas Robert (pour sa
% gentillesse infinie), Emilien Garreau, Antoine Hoorelbeke, Paul Morel, Florent Mercier, et Oscar
% Bouvier. Et enfin aussi Timothée Lesort, Fabio Cermelli, Eduardo Valle et Arnaud Dapogny pour leur
% collaboration. Plus largement je remercie aussi l'ensemble de l'équipe du MLIA et Heuritech pour
% leur support et la bonne ambiance qu'ils ont apporté.

% Enfin, je veux remercier mes proches. À Jordan et Camille qui m'ont tant soutenu cette dernière
% année. À David, Hugo, Alexandre, Thibault et Marie-Anne, Florent, Sarasvati, Benjamin, Charlotte,
% et tous ceux avec qui j'ai pu passer de bons moments. À ma famille, ma sœur Julie, mon père, ma
% mère et mes grand-parents pour leur soutien durant ces 26 ans de vie. J'insiste particulièrement
% sur l'éducation et la passion des sciences transmises par ma mère et ma grand-mère. Sans cela, rien
% n'aurait été possible. Et enfin merci à Epsilon pour ses ronronnements d'encouragement.


% \selectlanguage{english}
